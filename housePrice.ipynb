{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMawrQIpGC94TKWEK7cnwIn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srijitt/house-price-prediction/blob/main/housePrice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **House Price Prediction**\n",
        "\n",
        "In this notebook, I have created my first Machine Learning project- using RandomForestRegressor, in scikit-learn package. This represents a basic model of how ML algorithms work. I have used a pre-defined dataset of the House Price details in India, imported from Kaggle.\n",
        "\n",
        "*Link to the dataset: [here](https://www.kaggle.com/datasets/mohamedafsal007/house-price-dataset-of-india)*\n",
        "\n",
        "\n",
        "Libraries Used: \n",
        "*   `Pandas`: for organising and cleaning of dataset.\n",
        "*   `Scikit-learn`: for importing machine learning algorithms for our model.\n",
        "\n"
      ],
      "metadata": {
        "id": "7zSTOQavhALu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from os import path\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, r2_score"
      ],
      "metadata": {
        "id": "u9xzADxdVnZE"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we specify the path of the dataset, and then use the `read_csv()` method to read the file, in the form of a pandas dataframe. Then, we specify the *target*, i.e. the parameter we want to predict, which is `Price`. After that, we specify the features on which the model will train and predict. Keeping the model at basic level, parameters used to train the model are:\n",
        "\n",
        "\n",
        "*   Lot area\n",
        "*   Built year\n",
        "*   Number of bedrooms\n",
        "*   Number of bathrooms\n",
        "*   Number of floors\n",
        "\n",
        "Having done that, we split the data into `training` and `validation` datasets, using `train_test_split()` funtion."
      ],
      "metadata": {
        "id": "1wc8HmTPjbXA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Dataset\n",
        "path= 'House Price India.csv'\n",
        "home_data= pd.read_csv(path)\n",
        "\n",
        "# Specify target, training, and validation data\n",
        "y= home_data['Price']\n",
        "\n",
        "features= ['lot area', 'living area', 'condition of the house', 'Built Year', 'number of bedrooms', 'number of bathrooms', 'number of floors',\n",
        "           'Distance from the airport', 'Number of schools nearby']\n",
        "X= home_data[features]\n",
        "print(X.head())\n",
        "\n",
        "train_X, val_X, train_y, val_y= train_test_split(X, y, train_size=0.75, random_state=1)"
      ],
      "metadata": {
        "id": "yRomJXT1f0ty",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2910f452-abb4-4019-ed96-845df8eb789a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   lot area  living area  condition of the house  Built Year  \\\n",
            "0      9050         3650                       5        1921   \n",
            "1      4000         2920                       5        1909   \n",
            "2      9480         2910                       3        1939   \n",
            "3     42998         3310                       3        2001   \n",
            "4      4500         2710                       4        1929   \n",
            "\n",
            "   number of bedrooms  number of bathrooms  number of floors  \\\n",
            "0                   5                 2.50               2.0   \n",
            "1                   4                 2.50               1.5   \n",
            "2                   5                 2.75               1.5   \n",
            "3                   4                 2.50               2.0   \n",
            "4                   3                 2.00               1.5   \n",
            "\n",
            "   Distance from the airport  Number of schools nearby  \n",
            "0                         58                         2  \n",
            "1                         51                         2  \n",
            "2                         53                         1  \n",
            "3                         76                         3  \n",
            "4                         51                         1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once the training data is ready, we create the model, and fit the training data into it using `fit()` function. Then, we move on to make predictions using our model, by the `predict()` method. *Remember, fit the model using the training data- `train_X, train_y`, but make predictions using the validation data- `val_X`*"
      ],
      "metadata": {
        "id": "keot0ylilcKh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model= RandomForestRegressor(random_state=1)\n",
        "model.fit(train_X,train_y)\n",
        "\n",
        "# Predict\n",
        "predictions= model.predict(val_X)\n",
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rprsn3tff2ML",
        "outputId": "328bfc10-ee23-48d7-9e7b-f9a11320ca9a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 337050.25 1047900.5   282245.3  ... 1614919.5   332273.01  630333.49]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Error calculation is a very important step in ML predictions. Hence, we calculate `mean_absolute_error` and `R2 score` of our predictions by comparing the predicted results with our validation target data- `val_y`. "
      ],
      "metadata": {
        "id": "OWwlkgyymKoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mae= mean_absolute_error(predictions, val_y)\n",
        "r2= r2_score(val_y, predictions)\n",
        "\n",
        "print(\"Validation MAE for Random Forest Model: {:,.0f}\".format(mae))\n",
        "print(\"Validation R2 score for Random Forest Model: \", r2)"
      ],
      "metadata": {
        "id": "8-SfR63MVxQM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "237d1d60-71ec-4b76-aabb-bdf1bc633d1c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation MAE for Random Forest Model: 141,627\n",
            "Validation R2 score for Random Forest Model:  0.5871672568586559\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "R2 score criteria: (less than 0.3 - weak),\n",
        "                   (0.3 to 0.5 - moderate),\n",
        "                   (greater than 0.5 - strong)\n",
        "\n",
        "\n",
        "\n",
        "Since, this is my very first ML project, here are some suggested improvisations I would plan, as I delve deeper into machine-learning:\n",
        "\n",
        "*   Working on more concise model fitting\n",
        "*   Improving accuracy\n",
        "*   Adding more meaningful training data\n",
        "*   Managing overfitting and underfitting issues\n",
        "\n",
        "\n",
        "\n",
        "`End of Project`"
      ],
      "metadata": {
        "id": "oF_CSZ-YqttZ"
      }
    }
  ]
}